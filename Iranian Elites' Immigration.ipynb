{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1ffd2f76",
   "metadata": {},
   "source": [
    "# Iranian Elites' Immigration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a880c0d5",
   "metadata": {},
   "source": [
    "## 1.Initialization\n",
    "- Importing libraries\n",
    "- loading datasets, including:\n",
    "    - Travel History Data\n",
    "    - Label (Elite or not?)\n",
    "    - Gender\n",
    "    - Birth\n",
    "    - Konkour\n",
    "    - Olympiad\n",
    "- Building datesets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1750349",
   "metadata": {},
   "source": [
    "## 1.1 Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c1f12d4d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import timedelta\n",
    "from dateutil.relativedelta import relativedelta\n",
    "import statsmodels as sm\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "import statistics\n",
    "from scipy.stats import ttest_1samp\n",
    "from statsmodels.api import add_constant\n",
    "import math\n",
    "from scipy.stats import norm\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import timeit\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "21af1896",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "path=r'C:\\Users\\Marziyeh\\Downloads'\n",
    "os.chdir(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2511dcd9",
   "metadata": {},
   "source": [
    "## 1.2 Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "687036f8",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Marziyeh\\Downloads\\Migration 14010420 (2).ipynb Cell 7\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Marziyeh/Downloads/Migration%2014010420%20%282%29.ipynb#W6sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m Data_Part1 \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mread_excel (\u001b[39mr\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mTravel History, V3.xlsx\u001b[39;49m\u001b[39m'\u001b[39;49m,sheet_name\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mPart 1\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Marziyeh/Downloads/Migration%2014010420%20%282%29.ipynb#W6sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m Data_Part2 \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mread_excel (\u001b[39mr\u001b[39m\u001b[39m'\u001b[39m\u001b[39mTravel History, V3.xlsx\u001b[39m\u001b[39m'\u001b[39m,sheet_name\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mPart 2\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Marziyeh/Downloads/Migration%2014010420%20%282%29.ipynb#W6sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m Data\u001b[39m=\u001b[39mpd\u001b[39m.\u001b[39mconcat([Data_Part1, Data_Part2])\n",
      "File \u001b[1;32mc:\\Users\\Marziyeh\\anaconda3\\lib\\site-packages\\pandas\\util\\_decorators.py:311\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    305\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(args) \u001b[39m>\u001b[39m num_allow_args:\n\u001b[0;32m    306\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[0;32m    307\u001b[0m         msg\u001b[39m.\u001b[39mformat(arguments\u001b[39m=\u001b[39marguments),\n\u001b[0;32m    308\u001b[0m         \u001b[39mFutureWarning\u001b[39;00m,\n\u001b[0;32m    309\u001b[0m         stacklevel\u001b[39m=\u001b[39mstacklevel,\n\u001b[0;32m    310\u001b[0m     )\n\u001b[1;32m--> 311\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Marziyeh\\anaconda3\\lib\\site-packages\\pandas\\io\\excel\\_base.py:457\u001b[0m, in \u001b[0;36mread_excel\u001b[1;34m(io, sheet_name, header, names, index_col, usecols, squeeze, dtype, engine, converters, true_values, false_values, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, parse_dates, date_parser, thousands, decimal, comment, skipfooter, convert_float, mangle_dupe_cols, storage_options)\u001b[0m\n\u001b[0;32m    455\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(io, ExcelFile):\n\u001b[0;32m    456\u001b[0m     should_close \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m--> 457\u001b[0m     io \u001b[39m=\u001b[39m ExcelFile(io, storage_options\u001b[39m=\u001b[39;49mstorage_options, engine\u001b[39m=\u001b[39;49mengine)\n\u001b[0;32m    458\u001b[0m \u001b[39melif\u001b[39;00m engine \u001b[39mand\u001b[39;00m engine \u001b[39m!=\u001b[39m io\u001b[39m.\u001b[39mengine:\n\u001b[0;32m    459\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    460\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mEngine should not be specified when passing \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    461\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39man ExcelFile - ExcelFile already has the engine set\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    462\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\Marziyeh\\anaconda3\\lib\\site-packages\\pandas\\io\\excel\\_base.py:1419\u001b[0m, in \u001b[0;36mExcelFile.__init__\u001b[1;34m(self, path_or_buffer, engine, storage_options)\u001b[0m\n\u001b[0;32m   1416\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mengine \u001b[39m=\u001b[39m engine\n\u001b[0;32m   1417\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstorage_options \u001b[39m=\u001b[39m storage_options\n\u001b[1;32m-> 1419\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reader \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_engines[engine](\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_io, storage_options\u001b[39m=\u001b[39;49mstorage_options)\n",
      "File \u001b[1;32mc:\\Users\\Marziyeh\\anaconda3\\lib\\site-packages\\pandas\\io\\excel\\_openpyxl.py:524\u001b[0m, in \u001b[0;36mOpenpyxlReader.__init__\u001b[1;34m(self, filepath_or_buffer, storage_options)\u001b[0m\n\u001b[0;32m    509\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\n\u001b[0;32m    510\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m    511\u001b[0m     filepath_or_buffer: FilePath \u001b[39m|\u001b[39m ReadBuffer[\u001b[39mbytes\u001b[39m],\n\u001b[0;32m    512\u001b[0m     storage_options: StorageOptions \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m    513\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    514\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    515\u001b[0m \u001b[39m    Reader using openpyxl engine.\u001b[39;00m\n\u001b[0;32m    516\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    522\u001b[0m \u001b[39m        passed to fsspec for appropriate URLs (see ``_get_filepath_or_buffer``)\u001b[39;00m\n\u001b[0;32m    523\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 524\u001b[0m     import_optional_dependency(\u001b[39m\"\u001b[39;49m\u001b[39mopenpyxl\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[0;32m    525\u001b[0m     \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m(filepath_or_buffer, storage_options\u001b[39m=\u001b[39mstorage_options)\n",
      "File \u001b[1;32mc:\\Users\\Marziyeh\\anaconda3\\lib\\site-packages\\pandas\\compat\\_optional.py:138\u001b[0m, in \u001b[0;36mimport_optional_dependency\u001b[1;34m(name, extra, errors, min_version)\u001b[0m\n\u001b[0;32m    133\u001b[0m msg \u001b[39m=\u001b[39m (\n\u001b[0;32m    134\u001b[0m     \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mMissing optional dependency \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00minstall_name\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m. \u001b[39m\u001b[39m{\u001b[39;00mextra\u001b[39m}\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    135\u001b[0m     \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mUse pip or conda to install \u001b[39m\u001b[39m{\u001b[39;00minstall_name\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    136\u001b[0m )\n\u001b[0;32m    137\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 138\u001b[0m     module \u001b[39m=\u001b[39m importlib\u001b[39m.\u001b[39;49mimport_module(name)\n\u001b[0;32m    139\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mImportError\u001b[39;00m:\n\u001b[0;32m    140\u001b[0m     \u001b[39mif\u001b[39;00m errors \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mraise\u001b[39m\u001b[39m\"\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\Marziyeh\\anaconda3\\lib\\importlib\\__init__.py:127\u001b[0m, in \u001b[0;36mimport_module\u001b[1;34m(name, package)\u001b[0m\n\u001b[0;32m    125\u001b[0m             \u001b[39mbreak\u001b[39;00m\n\u001b[0;32m    126\u001b[0m         level \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m--> 127\u001b[0m \u001b[39mreturn\u001b[39;00m _bootstrap\u001b[39m.\u001b[39;49m_gcd_import(name[level:], package, level)\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1030\u001b[0m, in \u001b[0;36m_gcd_import\u001b[1;34m(name, package, level)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1007\u001b[0m, in \u001b[0;36m_find_and_load\u001b[1;34m(name, import_)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:986\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[1;34m(name, import_)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:680\u001b[0m, in \u001b[0;36m_load_unlocked\u001b[1;34m(spec)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap_external>:850\u001b[0m, in \u001b[0;36mexec_module\u001b[1;34m(self, module)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:228\u001b[0m, in \u001b[0;36m_call_with_frames_removed\u001b[1;34m(f, *args, **kwds)\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\Marziyeh\\anaconda3\\lib\\site-packages\\openpyxl\\__init__.py:5\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m# Copyright (c) 2010-2022 openpyxl\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mopenpyxl\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcompat\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mnumbers\u001b[39;00m \u001b[39mimport\u001b[39;00m NUMPY\n\u001b[1;32m----> 5\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mopenpyxl\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mxml\u001b[39;00m \u001b[39mimport\u001b[39;00m DEFUSEDXML, LXML\n\u001b[0;32m      6\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mopenpyxl\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mworkbook\u001b[39;00m \u001b[39mimport\u001b[39;00m Workbook\n\u001b[0;32m      7\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mopenpyxl\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mreader\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mexcel\u001b[39;00m \u001b[39mimport\u001b[39;00m load_workbook \u001b[39mas\u001b[39;00m \u001b[39mopen\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\Marziyeh\\anaconda3\\lib\\site-packages\\openpyxl\\xml\\__init__.py:26\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mlxml_env_set\u001b[39m():\n\u001b[0;32m     23\u001b[0m     \u001b[39mreturn\u001b[39;00m os\u001b[39m.\u001b[39menviron\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mOPENPYXL_LXML\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mTrue\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mTrue\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m---> 26\u001b[0m LXML \u001b[39m=\u001b[39m lxml_available() \u001b[39mand\u001b[39;00m lxml_env_set()\n\u001b[0;32m     29\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdefusedxml_available\u001b[39m():\n\u001b[0;32m     30\u001b[0m     \u001b[39mtry\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\Marziyeh\\anaconda3\\lib\\site-packages\\openpyxl\\xml\\__init__.py:10\u001b[0m, in \u001b[0;36mlxml_available\u001b[1;34m()\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mlxml_available\u001b[39m():\n\u001b[0;32m      9\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 10\u001b[0m         \u001b[39mfrom\u001b[39;00m \u001b[39mlxml\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39metree\u001b[39;00m \u001b[39mimport\u001b[39;00m LXML_VERSION\n\u001b[0;32m     11\u001b[0m         LXML \u001b[39m=\u001b[39m LXML_VERSION \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m (\u001b[39m3\u001b[39m, \u001b[39m3\u001b[39m, \u001b[39m1\u001b[39m, \u001b[39m0\u001b[39m)\n\u001b[0;32m     12\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m LXML:\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:398\u001b[0m, in \u001b[0;36mparent\u001b[1;34m(self)\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "Data_Part1 = pd.read_excel (r'Travel History, V3.xlsx',sheet_name='Part 1')\n",
    "Data_Part2 = pd.read_excel (r'Travel History, V3.xlsx',sheet_name='Part 2')\n",
    "Data=pd.concat([Data_Part1, Data_Part2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfefc452",
   "metadata": {},
   "outputs": [],
   "source": [
    "Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c40109c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "Label=pd.read_excel (r'Label.xlsx',sheet_name='Sheet1')\n",
    "Label= Label[Label['Elite'] == 1]\n",
    "Label.drop(\"Elite\",axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60ee3b51",
   "metadata": {},
   "outputs": [],
   "source": [
    "Konkour= pd.read_excel (r'Konkour.xlsx',sheet_name='Konkour')\n",
    "Olympiad= pd.read_excel (r'Olympiad 80-96.xlsx',sheet_name='Olympiad 80-96')\n",
    "Birth_Data= pd.read_excel (r'BirthDate_f.xlsx',sheet_name='Table53')\n",
    "Gender= pd.read_excel (r'gendef_f.xlsx',sheet_name='gender_f_')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bd38b40",
   "metadata": {},
   "source": [
    "## 1.3 Build Dataset\n",
    "### 1.3.1 Info Dataset\n",
    "The info dateset merges merges all detasets except travel history. So, this dataset consists of information about Birth, gender, and performance in konkour and olympiad."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "965fbed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "Info=pd.merge(\n",
    "    left=Label,\n",
    "    right=Birth_Data,\n",
    "    left_on=\"Label\",\n",
    "    right_on=\"Label\",\n",
    "    how=\"left\"\n",
    ")\n",
    "Info=pd.merge(\n",
    "    left=Info,\n",
    "    right=Gender,\n",
    "    left_on=\"Label\",\n",
    "    right_on=\"Label\",\n",
    "    how=\"left\"\n",
    ")\n",
    "Info=pd.merge(\n",
    "    left=Info,\n",
    "    right=Konkour,\n",
    "    left_on=\"Label\",\n",
    "    right_on=\"Label\",\n",
    "    how=\"left\"\n",
    ")\n",
    "Info.drop(\"Elite\",axis=1,inplace=True)\n",
    "Info=pd.merge(\n",
    "    left=Info,\n",
    "    right=Olympiad,\n",
    "    left_on=\"Label\",\n",
    "    right_on=\"Label\",\n",
    "    how=\"left\"\n",
    ")\n",
    "Info = Info.rename(columns={'birth_date': 'Birth', 'gender_f': 'Gender','year': 'olympiad_date','field': 'olympiad_field'})\n",
    "Info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00d411eb",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df=Data.dropna(subset=[\"تاریخ رخداد\"])  \n",
    "df[\"سامانه\"].value_counts()\n",
    "df=df.loc[:, ['کد','تاریخ رخداد','سامانه','کشور']]\n",
    "\n",
    "state=np.zeros(len(df))\n",
    "for i in range(len(df)):\n",
    "    if df.iloc[i][2]==\"ورود به مرز\":\n",
    "        state[i]=int(0)\n",
    "    elif df.iloc[i][2]==\"خروج از مرز\":\n",
    "        state[i]=int(1)      \n",
    "state=pd.DataFrame(state)\n",
    "\n",
    "df.insert(2, \"state\", state, True)\n",
    "df.drop('سامانه', inplace=True, axis=1)\n",
    "df = df.rename(columns={'کد': 'Code', 'تاریخ رخداد': 'Date','کشور': 'Country'})\n",
    "\n",
    "df['Year']= df['Date'].map(lambda x: str(x)[:-12])    \n",
    "df['Month']= df['Date'].map(lambda x: str(x)[5:7])  \n",
    "df['Day']= df['Date'].map(lambda x: str(x)[8:10])  \n",
    "\n",
    "df=df.drop([\"Country\"],axis=1)\n",
    "\n",
    "df['Day']=pd.to_numeric(df['Day'], errors='coerce')\n",
    "df['Month']=pd.to_numeric(df['Month'], errors='coerce')\n",
    "df['Year']=pd.to_numeric(df['Year'], errors='coerce')\n",
    "\n",
    "df['Days']=pd.DataFrame(np.zeros(len(df)))\n",
    "\n",
    "for i in range(len(df)):\n",
    "    if df['Month'].iloc[i]<7:\n",
    "        month_length=31*df['Month'].iloc[i]\n",
    "    else:\n",
    "        month_length=31*6+30*(df['Month'].iloc[i]-6)\n",
    "    df['Days'].iloc[i]=365*(df['Year'].iloc[i]-1385)+df['Day'].iloc[i]+month_length\n",
    "    \n",
    "df=df.sort_values(['Code', 'Days'], ascending=[True, True])\n",
    "\n",
    "df['Year']=pd.to_numeric(df['Year'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b532c08d",
   "metadata": {},
   "source": [
    "### 1.3.2 State and Date Datasets\n",
    "The raw Travel History data consists of travel records for our id s. Each row, shows a specific travel record for an id. We need a dataset that integrates all travel dates and status (whether the passenger leaves Iran or ruturns back), the former is Date dataset and the latter is State. \n",
    "In Date dataset, each row shows an id and all travel dates. In State dataset, each row shows an id and the status of subsequent travel dates. The two datasets are complementary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a02b996",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "Date=[]\n",
    "State=[]\n",
    "i=0\n",
    "while i<len(df):\n",
    "    Date_row=[]\n",
    "    State_row=[]\n",
    "    Date_row.append(df['Code'].iloc[i])\n",
    "    State_row.append(df['Code'].iloc[i])\n",
    "    j=0\n",
    " \n",
    "    while df['Code'].iloc[i+j]==df['Code'].iloc[i]:\n",
    "        Date_row.append(df['Days'].iloc[i+j])\n",
    "        State_row.append(df['state'].iloc[i+j])\n",
    "        j=j+1\n",
    "        if i+j+1>len(df):\n",
    "            break\n",
    "    Date.append(Date_row)\n",
    "    State.append(State_row)\n",
    "    i=i+j\n",
    "\n",
    "Date=pd.DataFrame(Date).iloc[:,0:100]\n",
    "State=pd.DataFrame(State).iloc[:,0:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1f694cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "Date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8df8ef3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "State"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c1b070d",
   "metadata": {},
   "outputs": [],
   "source": [
    "State.loc[State[0]==1132161].dropna(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1e461c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df['Code']==1132161]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5104da43",
   "metadata": {},
   "source": [
    "### 1.3.3 Other Datasets\n",
    "Now, we may use a subset of previous datasets to work on. For instance, the travel history for elites with a background in olympiad.\n",
    "Please construct the subsequent datesets in related sections. For exmple, please build datasets which are related to olympiad in the Olympiad section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f993887",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Check_Olympiad=pd.merge(\n",
    "    left=Olympiad,\n",
    "    right=State,\n",
    "    left_on=\"Label\",\n",
    "    right_on=State[0],\n",
    "    how=\"left\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02db7999",
   "metadata": {},
   "source": [
    "### 1.3.4 Export and Import Results\n",
    "For the purpose of speeding up, please save results which reproduction are time consuming in excel files, to avoid the reproduction process. We may reload them later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "140a098c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "Date.to_excel(r'Date.xlsx', index = False)\n",
    "State.to_excel(r'State.xlsx', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c339e9a3",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "Date= pd.read_excel (r'Date.xlsx',sheet_name='Sheet1')\n",
    "State= pd.read_excel (r'State.xlsx',sheet_name='Sheet1')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7febb80",
   "metadata": {},
   "source": [
    "## 2 Define Migrants\n",
    "- Who is a migrant? We do not have a solid answer for the question. The initial answer is a citizen who is out of a country for more than 400 days in a 2-year period is assumed as a migrant, till he or she returns to the country and stays there such that the number of days exceeds 400 days in the 2-year period, this way we may recognize a negative migration.\n",
    "- In this section, first we have eveluated different scenarios for defining migrants, and we run multiple sensitivity analysis on Duration Scenarios (for example 2 years in the initial definition), and Acceptable Duration Scenarios (for example 400 days in the initial definition).\n",
    "- In the last part, we have defined migrants and negative migrants based on our definition."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c43deebe",
   "metadata": {},
   "source": [
    "### 2.1 Sensitivity Analysis on Duration and Thereshold (Algorithm 1: atleast 1-time migration)\n",
    "In this algorithm, we define a person as a migrant if he or she spends more than x days out of Iran in any y-year period. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "688fa169",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "Scenario_column=[]\n",
    "Duration_Scenarios=[500,600,700,800]\n",
    "Acceptable_Duration_Scenarios=[250,300,350,400,450]\n",
    "for Duration in (Duration_Scenarios):\n",
    "    start=timeit.default_timer()\n",
    "    Scenario_row=[]\n",
    "    for Acceptable_Duration in (Acceptable_Duration_Scenarios):\n",
    "        Immigrant=0\n",
    "        i=0\n",
    "        while i<len(State):\n",
    "            j=0\n",
    "            res=0\n",
    "            Date_Prime=Date.iloc[i][1:]\n",
    "            State_Prime=State.iloc[i][1:]\n",
    "            Date_State_Prime=pd.concat([Date.iloc[i][1:], State.iloc[i][1:]], axis=1, join='inner')\n",
    "            Date_State_Prime=Date_State_Prime.dropna()\n",
    "            Date_Prime=np.array(Date_State_Prime.iloc[:,0])\n",
    "            State_Prime=np.array(Date_State_Prime.iloc[:,1])\n",
    "            while j<len(State_Prime):\n",
    "                if res==1:\n",
    "                    break\n",
    "                Time_Origin=Date_Prime[j]\n",
    "                for k in range(-Duration,0,20):\n",
    "                    Starting_point=max(Time_Origin+k,0)\n",
    "                    Ending_point=Starting_point+Duration\n",
    "                    index = np.where(np.logical_and(Date_Prime>=Starting_point, Date_Prime<=Ending_point))\n",
    "                    index=np.array(index)\n",
    "                    count=0\n",
    "                    if State_Prime[index[0][0]]==0:\n",
    "                        count+=Date_Prime[index[0][0]]-Starting_point\n",
    "                    if State_Prime[index[0][len(index[0])-1]]==1:\n",
    "                        count+=Ending_point-Date_Prime[index[0][len(index[0])-1]]   \n",
    "                    for s in range(len(index[0])-1):\n",
    "                        if State_Prime[index[0][s]]==1:\n",
    "                            count+=Date_Prime[index[0][s+1]]-Date_Prime[index[0][s]]\n",
    "                    if count>Acceptable_Duration:\n",
    "                        res=1\n",
    "                        Immigrant+=1\n",
    "                        break \n",
    "                j+=1\n",
    "            i+=1\n",
    "        Scenario_row.append(Immigrant/109301)   \n",
    "        stop = timeit.default_timer()\n",
    "        print(Acceptable_Duration)\n",
    "        print(Duration)\n",
    "        print(stop-start)\n",
    "        print(\"****\")\n",
    "    Scenario_column.append(Scenario_row)\n",
    "Scenario_column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85521ced",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "Result=pd.DataFrame(Scenario_column)\n",
    "Result.columns=[250,300,350,400,450]\n",
    "Result.index=[500,600,700,800]\n",
    "Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e8e0b3f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "Date.loc[Date[0]==1069620].loc[:,0:15]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfc05ca3",
   "metadata": {},
   "source": [
    "### 2.2 Sensitivity Analysis on Duration and Thereshold (Algorithm 2: last 2 year)\n",
    "In this algorithm, we define a person as a migrant if he or she spends more than x days out of Iran in the last y years."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "421b3cef",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Duration_Scenarios=[500,600,700,800]\n",
    "# Acceptable_Duration_Scenarios=[250,300,350,400,450]\n",
    "Duration_Scenarios=[500,600,700,800]\n",
    "Acceptable_Duration_Scenarios=[250,300,350,400,450]\n",
    "Starting_point=13505\n",
    "Scenario_column=[]\n",
    "for Duration in (Duration_Scenarios):\n",
    "    start=timeit.default_timer()\n",
    "    Scenario_row=[]\n",
    "    for Acceptable_Duration in (Acceptable_Duration_Scenarios):\n",
    "        Immigrant=0\n",
    "        i=0\n",
    "        while i<len(State):\n",
    "            j=0\n",
    "            res=0\n",
    "            Date_Prime=Date.iloc[i][1:]\n",
    "            State_Prime=State.iloc[i][1:]\n",
    "            Date_State_Prime=pd.concat([Date.iloc[i][1:], State.iloc[i][1:]], axis=1, join='inner')\n",
    "            Date_State_Prime=Date_State_Prime.dropna()\n",
    "            Date_Prime=np.array(Date_State_Prime.iloc[:,0])\n",
    "            State_Prime=np.array(Date_State_Prime.iloc[:,1])\n",
    "            Ending_point=Starting_point+Duration\n",
    "            index = np.where(np.logical_and(Date_Prime>=Starting_point, Date_Prime<=Ending_point))\n",
    "            index=np.array(index)\n",
    "            count=0\n",
    "            if(len(index[0]))==0:\n",
    "                t=len(Date_Prime)-1\n",
    "                while Date_Prime[t]>Starting_point and t>0:\n",
    "                    t=t-1\n",
    "                if State_Prime[t]==1:\n",
    "                    res=1\n",
    "                    Immigrant+=1\n",
    "            else:          \n",
    "                if State_Prime[index[0][0]]==0:\n",
    "                    count+=Date_Prime[index[0][0]]-Starting_point\n",
    "                if State_Prime[index[0][len(index[0])-1]]==1:\n",
    "                    count+=Ending_point-Date_Prime[index[0][len(index[0])-1]]   \n",
    "                for s in range(len(index[0])-1):\n",
    "                    if State_Prime[index[0][s]]==1:\n",
    "                        count+=Date_Prime[index[0][s+1]]-Date_Prime[index[0][s]]\n",
    "                if count>Acceptable_Duration:\n",
    "                    res=1\n",
    "                    Immigrant+=1\n",
    "            i+=1\n",
    "#             print(i)\n",
    "#             print(res)\n",
    "#             print(count)\n",
    "#             print(Date_Prime)\n",
    "#             print(State_Prime)\n",
    "#             print(\"***\")\n",
    "        Scenario_row.append(Immigrant/109301)   \n",
    "        stop = timeit.default_timer()\n",
    "        print(Acceptable_Duration)\n",
    "        print(Duration)\n",
    "        print(stop-start)\n",
    "        print(\"****\")\n",
    "    Scenario_column.append(Scenario_row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0594b76d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "Result_Last=pd.DataFrame(Scenario_column)\n",
    "Result_Last\n",
    "Result_Last.columns=[250,300,350,400,450]\n",
    "Result_Last.index=[500,600,700,800]\n",
    "Result_Last"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f11932d",
   "metadata": {},
   "source": [
    "### 1.3 Sensitivity Analysis on Duration and Percent Thereshold (Algorithm 3: non-rolling 2 year)\n",
    "In fact, there should be reasonable relation between our Duration_Scenarios and Acceptable_Duration_Scenarios. It is more meaningful to define a time period in the Acceptable_Duration_Scenarios based on shares. For example, we may define a person as a migrant if he or she spends more than 50 percent of a value is Duration_Scenarios out of Iran. This scenario seems more acceptable!\n",
    "We have eveluated such scenarios in this section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "971be749",
   "metadata": {},
   "outputs": [],
   "source": [
    "Duration_Scenarios=[500,600,700,800]\n",
    "Acceptable_Duration_Scenarios=[250,300,350,400,450]\n",
    "Duration_Scenarios=[365,547,730,912,1095]\n",
    "Starting_point=4015\n",
    "Scenario_column=[]\n",
    "length=len(State)\n",
    "for Duration in (Duration_Scenarios):\n",
    "    Acceptable_Duration_Scenarios=[0.3*Duration,0.4*Duration,0.5*Duration,0.6*Duration,0.7*Duration]\n",
    "    print(Acceptable_Duration_Scenarios)\n",
    "    start=timeit.default_timer()\n",
    "    Scenario_row=[]\n",
    "    for Acceptable_Duration in (Acceptable_Duration_Scenarios):\n",
    "        Immigrant=0\n",
    "        i=0\n",
    "        while i<length:\n",
    "            j=0\n",
    "            res=0\n",
    "            Date_Prime=Date.iloc[i][1:]\n",
    "            State_Prime=State.iloc[i][1:]\n",
    "            Date_State_Prime=pd.concat([Date.iloc[i][1:], State.iloc[i][1:]], axis=1, join='inner')\n",
    "            Date_State_Prime=Date_State_Prime.dropna()\n",
    "            Date_Prime=np.array(Date_State_Prime.iloc[:,0])\n",
    "            State_Prime=np.array(Date_State_Prime.iloc[:,1])\n",
    "            Ending_point=Starting_point+Duration\n",
    "            index = np.where(np.logical_and(Date_Prime>=Starting_point, Date_Prime<=Ending_point))\n",
    "            index=np.array(index)\n",
    "            count=0\n",
    "            if(len(index[0]))==0:\n",
    "                t=len(Date_Prime)-1\n",
    "                while Date_Prime[t]>Starting_point and t>0:\n",
    "                    t=t-1\n",
    "                if State_Prime[t]==1:\n",
    "                    res=1\n",
    "                    Immigrant+=1\n",
    "            else:          \n",
    "                if State_Prime[index[0][0]]==0:\n",
    "                    count+=Date_Prime[index[0][0]]-Starting_point\n",
    "                if State_Prime[index[0][len(index[0])-1]]==1:\n",
    "                    count+=Ending_point-Date_Prime[index[0][len(index[0])-1]]   \n",
    "                for s in range(len(index[0])-1):\n",
    "                    if State_Prime[index[0][s]]==1:\n",
    "                        count+=Date_Prime[index[0][s+1]]-Date_Prime[index[0][s]]\n",
    "                if count>Acceptable_Duration:\n",
    "                    res=1\n",
    "                    Immigrant+=1\n",
    "            i+=1\n",
    "        Scenario_row.append(Immigrant/length) \n",
    "        print(Immigrant/length)\n",
    "        stop = timeit.default_timer()\n",
    "        print(Acceptable_Duration)\n",
    "        print(Duration)\n",
    "        print(stop-start)\n",
    "        print(\"****\")\n",
    "    Scenario_column.append(Scenario_row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29ce9d56",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Final_Result=pd.DataFrame(Scenario_column)\n",
    "Final_Result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f513160d",
   "metadata": {},
   "source": [
    "### 1.4 Determine Migrants\n",
    "Finally, we have defined migrants based on our chosen scenario. The Info Migration dataset define migration and negative migration records for each id."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40a31602",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "Immigrant=[]\n",
    "Immigrant_Negative=[]\n",
    "Immigrant_Final_Status=[]\n",
    "Immigrantion_Date=[]\n",
    "Duration=730\n",
    "Acceptable_Duration=400\n",
    "Migration_Background=[]\n",
    "Migration_Background_row=[]\n",
    "Migration_Background_Status=[]\n",
    "Migration_Background_Status_row=[]\n",
    "Info_Migration=[]\n",
    "Info_Migration_row=[]\n",
    "i=0\n",
    "while i<len(State):\n",
    "    Migration_Background_row=[]\n",
    "    Migration_Background_Status_row=[]\n",
    "    Info_Migration_row=[]\n",
    "    Migration_Background_row.append(Date.iloc[i][0])\n",
    "    Migration_Background_Status_row.append(Date.iloc[i][0])\n",
    "    Info_Migration_row.append(Date.iloc[i][0])\n",
    "    j=0\n",
    "    Date_Prime=Date.iloc[i][1:]\n",
    "    State_Prime=State.iloc[i][1:]\n",
    "    Date_State_Prime=pd.concat([Date.iloc[i][1:], State.iloc[i][1:]], axis=1, join='inner')\n",
    "    Date_State_Prime=Date_State_Prime.dropna()\n",
    "    Date_Prime=np.array(Date_State_Prime.iloc[:,0])\n",
    "    State_Prime=np.array(Date_State_Prime.iloc[:,1])\n",
    "    Status=0\n",
    "    while j<len(State_Prime):\n",
    "        if Date_Prime[j]<4745:\n",
    "            res=0\n",
    "            Starting_point=Date_Prime[j]\n",
    "            Ending_point=Starting_point+Duration\n",
    "            index = np.where(np.logical_and(Date_Prime>=Starting_point, Date_Prime<=Ending_point))\n",
    "            index=np.array(index)\n",
    "            count=0\n",
    "            for s in range(len(index[0])-1):\n",
    "                if State_Prime[index[0][s]]==1:\n",
    "                    count+=Date_Prime[index[0][s+1]]-Date_Prime[index[0][s]]\n",
    "            if State_Prime[index[0][-1]]==1 :\n",
    "                count+=Ending_point-Date_Prime[index[0][-1]]   \n",
    "            if count>Acceptable_Duration:\n",
    "                res=1\n",
    "\n",
    "            if Status!=res:\n",
    "                Status=res\n",
    "                Migration_Background_row.append(Date_Prime[j])\n",
    "                Migration_Background_Status_row.append(Status)\n",
    "        j+=1\n",
    "    if len(Migration_Background_row)>1:\n",
    "        Info_Migration_row.append(1)\n",
    "        if len(Migration_Background_row)>2:\n",
    "            Info_Migration_row.append(1)\n",
    "        else:\n",
    "            Info_Migration_row.append(0)\n",
    "        Info_Migration_row.append(Migration_Background_Status_row[-1])\n",
    "        Info_Migration_row.append(Migration_Background_row[1])\n",
    "        Info_Migration_row.append(State_Prime[-1])\n",
    "        Info_Migration_row.append(math.modf(Migration_Background_row[1]/365)[1]+1+1385-Info.iloc[i][1])\n",
    "        \n",
    "    else:\n",
    "        Info_Migration_row.append('NaN')\n",
    "        Info_Migration_row.append('NaN')\n",
    "        Info_Migration_row.append('NaN')\n",
    "        Info_Migration_row.append('NaN')\n",
    "        Info_Migration_row.append('NaN')\n",
    "        Info_Migration_row.append('NaN')\n",
    "\n",
    "            \n",
    "    Migration_Background.append(Migration_Background_row)\n",
    "    Migration_Background_Status.append(Migration_Background_Status_row)\n",
    "    Info_Migration.append(Info_Migration_row)\n",
    "    i+=1\n",
    "    \n",
    "Info_Migration=pd.DataFrame(Info_Migration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee013e0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Dataset=pd.merge(\n",
    "    left=Info,\n",
    "    right=Info_Migration,\n",
    "    left_on=\"Label\",\n",
    "    right_on=Info_Migration[0],\n",
    "    how=\"left\"\n",
    ")\n",
    "Dataset.rename(columns = {0:'Label2', 1:'Positive_Migration',2:'Negative_Migration',3:'Final_Status',4:'Migration_Date', 5:'Current_Status', 6:'Migration_Age'}, inplace = True)\n",
    "Dataset.drop(['Label2'],axis=1,inplace=True)\n",
    "Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "506fabfd",
   "metadata": {},
   "source": [
    "# 3 Migration Summary Statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3b2b0ee",
   "metadata": {},
   "source": [
    "Here, we draw general results. We do not analyse konkour and olympiad data separately. Issues such as migration age (whether the migrant has a contribution in olympiad or konkour) are investigated here."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ed69bce",
   "metadata": {},
   "source": [
    "### 3.1 Migration rate vs year\n",
    "What is the total positive and negative migration rate in each year?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ab25bda",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "Migration_Positive=[]\n",
    "Migration_Negative=[]\n",
    "for i in range (len(Migration_Background)):\n",
    "    if len(Migration_Background[i])>0:\n",
    "        for j in range(len(Migration_Background[i])):\n",
    "            if Migration_Background_Status[i][j]==1:\n",
    "                Migration_Positive.append(math.modf(Migration_Background[i][j]/365)[1]+1385+1)\n",
    "            elif Migration_Background_Status[i][j]==0:\n",
    "                Migration_Negative.append(math.modf(Migration_Background[i][j]/365)[1]+1385+1)\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2f6c892",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.hist(Migration_Positive,bins=13,histtype='bar',density=True, \n",
    "         stacked=True, \n",
    "         edgecolor=\"#6A9662\",\n",
    "         color=\"#DDFFDD\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23c90504",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.hist(Migration_Negative,bins=14,density=True, \n",
    "         stacked=True, \n",
    "         edgecolor=\"#6A9662\",\n",
    "         color=\"#DDFFDD\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6f01494",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "Migration_Positive_Counter=np.zeros(15)\n",
    "Migration_Negative_Counter=np.zeros(15)\n",
    "for i in range(15):\n",
    "    Year=1385+i\n",
    "    Migration_Positive_Counter[i]=Migration_Positive.count(Year)\n",
    "    Migration_Negative_Counter[i]=Migration_Negative.count(Year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e57f773",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# set width of bar\n",
    "barWidth = 1\n",
    "fig = plt.subplots(figsize =(12, 8))\n",
    " \n",
    "# # set height of bar\n",
    "# IT = [12, 30, 1, 8, 22]\n",
    "# ECE = [28, 6, 16, 5, 10]\n",
    "# CSE = [29, 3, 24, 25, 17]\n",
    "\n",
    "# Set position of bar on X axis\n",
    "br1 = np.arange(len(Migration_Positive_Counter))\n",
    "#br2 = [x + barWidth for x in br1]\n",
    "\n",
    " \n",
    "# Make the plot\n",
    "plt.bar(br1, Migration_Positive_Counter, color ='r', width = barWidth,edgecolor ='grey', label ='Positive Migration', alpha=0.8)\n",
    "#plt.bar(br2, Migration_Negative_Counter, color ='g', width = barWidth,\n",
    "       # edgecolor ='grey', label ='Negative Migration', alpha=0.8)\n",
    "\n",
    "# Adding Xticks\n",
    "#plt.xlabel('Year', fontweight ='bold', fontsize = 15)\n",
    "plt.xlabel('Year', fontsize = 15)\n",
    "plt.ylabel('Migrants (Person)', fontsize = 15)\n",
    "plt.xticks([r + barWidth for r in range(len(Migration_Positive_Counter))],\n",
    "        ['1386', '1387', '1388', '1389','1390', '1391', '1392', '1393','1394','1395','1396','1397','1398','1399','1400'])\n",
    " \n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "901f15d7",
   "metadata": {},
   "source": [
    "### 3.2 Return back period\n",
    "For those who have a record of negative migration, how much time have they spent before they return back?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec67b90a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "Migration_Diff=[]\n",
    "for i in range (len(Migration_Background)):\n",
    "    if len(Migration_Background[i])>2:\n",
    "        for j in range(2,len(Migration_Background[i])):\n",
    "            Migration_Diff.append(Migration_Background[i][j]-Migration_Background[i][j-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8545e551",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.hist(Migration_Diff, bins=100)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e436899a",
   "metadata": {},
   "source": [
    "### 3.3 Migration Age\n",
    "How old was the migrant when he or she migrated for the first time?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c5b9743",
   "metadata": {},
   "outputs": [],
   "source": [
    "Dataset_Age=Dataset.dropna(subset = ['Migration_Date'])\n",
    "Dataset_Age\n",
    "Dataset['Migration_Age'].value_counts()[50]\n",
    "Dataset['Migration_Age'].hist\n",
    "Counter_Age=np.zeros(30)\n",
    "for i in range(20,50):\n",
    "    Counter_Age[i-20]=Dataset['Migration_Age'].value_counts()[i]\n",
    "plt.hist(Counter_Age)\n",
    "Counter_Age\n",
    "Migration_Age_List=Dataset['Migration_Age']\n",
    "#Migration_Age_List.dropna(inplace=True)\n",
    "Migration_Age_List=Dataset.dropna(subset = ['Migration_Age'])\n",
    "Migration_Age=Migration_Age_List['Migration_Age']\n",
    "Migration_Age\n",
    "Migration_Age.hist(bins=100)\n",
    "Dataset['Migration_Age'].value_counts()[]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b106986a",
   "metadata": {},
   "source": [
    "## 2 Migration vs Konkur Results \n",
    "Here, we want to draw conclusions about migrants who have a contribution in konkour."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69eb7b84",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "Dataset_Konkour=Dataset.dropna(subset = ['konkour_date'])\n",
    "Dataset_Konkour\n",
    "Dataset_Konkour.sort_values(by=['konkour_date'])\n",
    "Dataset_Konkour_Mashmool=Dataset_Konkour.loc[((Dataset_Konkour['konkour_field']=='هنر') & (Dataset_Konkour['konkour_rank'] <= 40)) | ((Dataset_Konkour['konkour_field']=='علوم ریاضی و فنی') & (Dataset_Konkour['konkour_rank'] <= 150)) | ((Dataset_Konkour['konkour_field']=='علوم انسانی') & (Dataset_Konkour['konkour_rank'] <= 100)) | ((Dataset_Konkour['konkour_field']=='علوم تجربی') & (Dataset_Konkour['konkour_rank'] <= 100))]\n",
    "Dataset_Konkour_Mashmool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b3a3581",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(Dataset_Konkour.loc[Dataset_Konkour['Positive_Migration'] == 1])/len(Dataset_Konkour)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71e55d91",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "Pop_Honar=[801,814,823,801,823,826,829,904,849,952,949,959,929,610,782]\n",
    "Pop_Riazi=[854,869,852,867,889,870,861,887,916,981,990,988,987,995,990]\n",
    "Pop_Tajrobi=[846,851,863,855,873,844,871,918,908,998,996,1000,996,992,999]\n",
    "Pop_Ensani=[820,851,841,838,836,866,855,897,905,998,989,993,992,991,997]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31d889b7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "Data_Konkur_Summary_Honar=Dataset_Konkour.loc[Dataset_Konkour['konkour_field'] ==\"هنر\"].loc[Dataset_Konkour['Positive_Migration'] == 1]\n",
    "Counter_Honar=np.zeros(15)\n",
    "Counter_Honar_percent=np.zeros(15)\n",
    "for i in range(15):\n",
    "    Year=1380+i\n",
    "    Counter_Honar[i]=Data_Konkur_Summary_Honar['konkour_date'].value_counts()[Year]\n",
    "    Counter_Honar_percent[i]=Counter_Honar[i]/Pop_Honar[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdb91503",
   "metadata": {},
   "outputs": [],
   "source": [
    "Data_Konkur_Summary_Honar_Mashmool=Dataset_Konkour_Mashmool.loc[Dataset_Konkour['konkour_field'] ==\"هنر\"].loc[Dataset_Konkour['Positive_Migration'] == 1]\n",
    "Counter_Honar_Mashmool=np.zeros(15)\n",
    "Counter_Honar_Mashmool_percent=np.zeros(15)\n",
    "for i in range(15):\n",
    "    Year=1380+i\n",
    "    Counter_Honar_Mashmool[i]=Data_Konkur_Summary_Honar_Mashmool['konkour_date'].value_counts()[Year]\n",
    "    Counter_Honar_Mashmool_percent[i]=Counter_Honar_Mashmool[i]/40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9ef9398",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set width of bar\n",
    "barWidth = 0.17\n",
    "fig = plt.subplots(figsize =(12, 8))\n",
    " \n",
    "# # set height of bar\n",
    "# IT = [12, 30, 1, 8, 22]\n",
    "# ECE = [28, 6, 16, 5, 10]\n",
    "# CSE = [29, 3, 24, 25, 17]\n",
    "\n",
    "# Set position of bar on X axis\n",
    "br1 = np.arange(len(Counter_Honar))\n",
    "br2 = [x + barWidth for x in br1]\n",
    " \n",
    "# Make the plot\n",
    "plt.bar(br1, Counter_Honar_percent, color ='r', width = barWidth,\n",
    "        edgecolor ='grey', label ='Top 1000 Participants', alpha=0.8)\n",
    "plt.bar(br2, Counter_Honar_Mashmool_percent, color ='g', width = barWidth,\n",
    "        edgecolor ='grey', label ='Recognized as Elite by Bonyad', alpha=0.8)\n",
    "\n",
    "\n",
    "# Adding Xticks\n",
    "#plt.xlabel('Year', fontweight ='bold', fontsize = 15)\n",
    "plt.xlabel('Year', fontsize = 15)\n",
    "plt.ylabel('Migrants-Honar (Percent)', fontsize = 15)\n",
    "plt.xticks([r + barWidth for r in range(len(Counter_Honar))],\n",
    "        ['1380', '1381', '1382', '1383', '1384','1385', '1386', '1387', '1388', '1389','1390', '1391', '1392', '1393','1394'])\n",
    " \n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff544e76",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "Data_Konkur_Summary_Riazi=Dataset_Konkour.loc[Dataset_Konkour['konkour_field'] ==\"علوم ریاضی و فنی\"].loc[Dataset_Konkour['Positive_Migration'] == 1]\n",
    "Counter_Riazi=np.zeros(15)\n",
    "#Counter_Riazi_percent=np.zeros(15)\n",
    "for i in range(15):\n",
    "    Year=1380+i\n",
    "    Counter_Riazi[i]=Data_Konkur_Summary_Riazi['konkour_date'].value_counts()[Year]\n",
    "    Counter_Riazi_percent[i]=Counter_Riazi[i]/Pop_Riazi[i]\n",
    "    \n",
    "Data_Konkur_Summary_Riazi_Mashmool=Dataset_Konkour_Mashmool.loc[Dataset_Konkour['konkour_field'] ==\"علوم ریاضی و فنی\"].loc[Dataset_Konkour['Positive_Migration'] == 1]\n",
    "Counter_Riazi_Mashmool=np.zeros(15)\n",
    "Counter_Riazi_Mashmool_percent=np.zeros(15)\n",
    "for i in range(15):\n",
    "    Year=1380+i\n",
    "    Counter_Riazi_Mashmool[i]=Data_Konkur_Summary_Riazi_Mashmool['konkour_date'].value_counts()[Year]\n",
    "    Counter_Riazi_Mashmool_percent[i]=Counter_Riazi_Mashmool[i]/150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa258b43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set width of bar\n",
    "barWidth = 0.17\n",
    "fig = plt.subplots(figsize =(12, 8))\n",
    " \n",
    "# # set height of bar\n",
    "# IT = [12, 30, 1, 8, 22]\n",
    "# ECE = [28, 6, 16, 5, 10]\n",
    "# CSE = [29, 3, 24, 25, 17]\n",
    "\n",
    "# Set position of bar on X axis\n",
    "br1 = np.arange(len(Counter_Riazi))\n",
    "br2 = [x + barWidth for x in br1]\n",
    " \n",
    "# Make the plot\n",
    "plt.bar(br1, Counter_Riazi_percent, color ='r', width = barWidth,\n",
    "        edgecolor ='grey', label ='Top 1000 Participants', alpha=0.8)\n",
    "plt.bar(br2, Counter_Riazi_Mashmool_percent, color ='g', width = barWidth,\n",
    "        edgecolor ='grey', label ='Recognized as Elite by Bonyad', alpha=0.8)\n",
    "\n",
    "\n",
    "# Adding Xticks\n",
    "#plt.xlabel('Year', fontweight ='bold', fontsize = 15)\n",
    "plt.xlabel('Year', fontsize = 15)\n",
    "plt.ylabel('Migrants-Honar (Percent)', fontsize = 15)\n",
    "plt.xticks([r + barWidth for r in range(len(Counter_Riazi))],\n",
    "        ['1380', '1381', '1382', '1383', '1384','1385', '1386', '1387', '1388', '1389','1390', '1391', '1392', '1393','1394'])\n",
    " \n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "072dc88f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "Data_Konkur_Summary_Tajrobi=Dataset_Konkour.loc[Dataset_Konkour['konkour_field'] ==\"علوم تجربی\"].loc[Dataset_Konkour['Positive_Migration'] == 1]\n",
    "Counter_Tajrobi=np.zeros(15)\n",
    "Counter_Tajrobi_percent=np.zeros(15)\n",
    "for i in range(15):\n",
    "    Year=1380+i\n",
    "    Counter_Tajrobi[i]=Data_Konkur_Summary_Tajrobi['konkour_date'].value_counts()[Year]\n",
    "    Counter_Tajrobi_percent[i]=Counter_Tajrobi[i]/Pop_Tajrobi[i]\n",
    "    \n",
    "Data_Konkur_Summary_Tajrobi_Mashmool=Dataset_Konkour_Mashmool.loc[Dataset_Konkour['konkour_field'] ==\"علوم تجربی\"].loc[Dataset_Konkour['Positive_Migration'] == 1]\n",
    "Counter_Tajrobi_Mashmool=np.zeros(15)\n",
    "Counter_Tajrobi_Mashmool_percent=np.zeros(15)\n",
    "for i in range(15):\n",
    "    Year=1380+i\n",
    "    Counter_Tajrobi_Mashmool[i]=Data_Konkur_Summary_Tajrobi_Mashmool['konkour_date'].value_counts()[Year]\n",
    "    Counter_Tajrobi_Mashmool_percent[i]=Counter_Tajrobi_Mashmool[i]/100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f2064a9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "Data_Konkur_Summary_Ensani=Dataset_Konkour.loc[Dataset_Konkour['konkour_field'] ==\"علوم انسانی\"].loc[Dataset_Konkour['Positive_Migration'] == 1]\n",
    "Data_Konkur_Summary_Ensani\n",
    "Counter_Ensani=np.zeros(15)\n",
    "Counter_Ensani_percent=np.zeros(15)\n",
    "for i in range(15):\n",
    "    Year=1380+i\n",
    "    Counter_Ensani[i]=Data_Konkur_Summary_Ensani['konkour_date'].value_counts()[Year]\n",
    "    Counter_Ensani_percent[i]=Counter_Ensani[i]/Pop_Ensani[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c47452ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "Data_Konkur_Summary_Ensani=Dataset_Konkour_Mashmool.loc[Dataset_Konkour['konkour_field'] ==\"علوم انسانی\"].loc[Dataset_Konkour['Positive_Migration'] == 1]\n",
    "Counter_Ensani=np.zeros(15)\n",
    "Counter_Ensani_percent=np.zeros(15)\n",
    "for i in range(15):\n",
    "    Year=1380+i\n",
    "    Counter_Ensani[i]=Data_Konkur_Summary_Ensani['konkour_date'].value_counts()[Year]\n",
    "    Counter_Ensani_percent[i]=Counter_Ensani[i]/Pop_Ensani[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ef1b849",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# set width of bar\n",
    "barWidth = 0.17\n",
    "fig = plt.subplots(figsize =(12, 8))\n",
    " \n",
    "# # set height of bar\n",
    "# IT = [12, 30, 1, 8, 22]\n",
    "# ECE = [28, 6, 16, 5, 10]\n",
    "# CSE = [29, 3, 24, 25, 17]\n",
    "\n",
    "# Set position of bar on X axis\n",
    "br1 = np.arange(len(Counter_Riazi))\n",
    "br2 = [x + barWidth for x in br1]\n",
    "br3 = [x + barWidth for x in br2]\n",
    "br4 = [x + barWidth for x in br3]\n",
    " \n",
    "# Make the plot\n",
    "plt.bar(br1, Counter_Riazi, color ='r', width = barWidth,\n",
    "        edgecolor ='grey', label ='Riazi', alpha=0.8)\n",
    "plt.bar(br2, Counter_Tajrobi, color ='g', width = barWidth,\n",
    "        edgecolor ='grey', label ='Tajrobi', alpha=0.8)\n",
    "plt.bar(br3, Counter_Ensani, color ='b', width = barWidth,\n",
    "        edgecolor ='grey', label ='Ensani', alpha=0.8)\n",
    "plt.bar(br4, Counter_Honar, color ='c', width = barWidth,\n",
    "        edgecolor ='grey', label ='Honar', alpha=0.8)\n",
    "\n",
    "# Adding Xticks\n",
    "#plt.xlabel('Year', fontweight ='bold', fontsize = 15)\n",
    "plt.xlabel('Year', fontsize = 15)\n",
    "plt.ylabel('Migrants (Person)', fontsize = 15)\n",
    "plt.xticks([r + barWidth for r in range(len(Counter_Riazi))],\n",
    "        ['1380', '1381', '1382', '1383', '1384','1385', '1386', '1387', '1388', '1389','1390', '1391', '1392', '1393','1394'])\n",
    " \n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaf1c5c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "A=pd.DataFrame(Counter_Riazi_percent)\n",
    "B=pd.DataFrame(Counter_Tajrobi_percent)\n",
    "C=pd.DataFrame(Counter_Ensani_percent)\n",
    "D=pd.DataFrame(Counter_Honar_percent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97eec1f1",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# set width of bar\n",
    "barWidth = 0.17\n",
    "fig = plt.subplots(figsize =(12, 8))\n",
    " \n",
    "# # set height of bar\n",
    "# IT = [12, 30, 1, 8, 22]\n",
    "# ECE = [28, 6, 16, 5, 10]\n",
    "# CSE = [29, 3, 24, 25, 17]\n",
    "\n",
    "# Set position of bar on X axis\n",
    "br1 = np.arange(len(Counter_Riazi))\n",
    "br2 = [x + barWidth for x in br1]\n",
    "br3 = [x + barWidth for x in br2]\n",
    "br4 = [x + barWidth for x in br3]\n",
    " \n",
    "# Make the plot\n",
    "plt.bar(br1, Counter_Riazi_percent, color ='r', width = barWidth,\n",
    "        edgecolor ='grey', label ='Riazi', alpha=0.8)\n",
    "plt.bar(br2, Counter_Tajrobi_percent, color ='g', width = barWidth,\n",
    "        edgecolor ='grey', label ='Tajrobi', alpha=0.8)\n",
    "plt.bar(br3, Counter_Ensani_percent, color ='b', width = barWidth,\n",
    "        edgecolor ='grey', label ='Ensani', alpha=0.8)\n",
    "plt.bar(br4, Counter_Honar_percent, color ='c', width = barWidth,\n",
    "        edgecolor ='grey', label ='Honar', alpha=0.8)\n",
    "\n",
    "# Adding Xticks\n",
    "#plt.xlabel('Year', fontweight ='bold', fontsize = 15)\n",
    "plt.xlabel('Year', fontsize = 15)\n",
    "plt.ylabel('Migrants (Percent)', fontsize = 15)\n",
    "plt.xticks([r + barWidth for r in range(len(Counter_Riazi))],\n",
    "        ['1380', '1381', '1382', '1383', '1384','1385', '1386', '1387', '1388', '1389','1390', '1391', '1392', '1393','1394'])\n",
    " \n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "534c8838",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set width of bar\n",
    "barWidth = 0.17\n",
    "fig = plt.subplots(figsize =(12, 8))\n",
    " \n",
    "# # set height of bar\n",
    "# IT = [12, 30, 1, 8, 22]\n",
    "# ECE = [28, 6, 16, 5, 10]\n",
    "# CSE = [29, 3, 24, 25, 17]\n",
    "\n",
    "# Set position of bar on X axis\n",
    "br1 = np.arange(len(Counter_Riazi))\n",
    "br2 = [x + barWidth for x in br1]\n",
    " \n",
    "# Make the plot\n",
    "plt.bar(br1, Counter_Riazi_percent, color ='r', width = barWidth,\n",
    "        edgecolor ='grey', label ='Riazi', alpha=0.8)\n",
    "plt.bar(br2, Counter_Tajrobi_percent, color ='g', width = barWidth,\n",
    "        edgecolor ='grey', label ='Tajrobi', alpha=0.8)\n",
    "\n",
    "# Adding Xticks\n",
    "#plt.xlabel('Year', fontweight ='bold', fontsize = 15)\n",
    "plt.xlabel('Year', fontsize = 15)\n",
    "plt.ylabel('Migrants (Percent)', fontsize = 15)\n",
    "plt.xticks([r + barWidth for r in range(len(Counter_Riazi))],\n",
    "        ['1380', '1381', '1382', '1383', '1384','1385', '1386', '1387', '1388', '1389','1390', '1391', '1392', '1393','1394'])\n",
    " \n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9782590",
   "metadata": {},
   "outputs": [],
   "source": [
    "Reshte=[\"علوم ریاضی و فنی\",\"علوم تجربی\",\"علوم انسانی\",\"هنر\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d858906",
   "metadata": {},
   "outputs": [],
   "source": [
    "Age_Matrix=[]\n",
    "Age_Matrix_Mashmool=[]\n",
    "for j in range(len(Reshte)):\n",
    "    Data_Konkur_Migrated=Dataset_Konkour.loc[Dataset_Konkour['konkour_field']==Reshte[j]].loc[Dataset_Konkour['Positive_Migration'] == 1]\n",
    "    Data_Konkur_Mashmool_Migrated=Dataset_Konkour_Mashmool.loc[Dataset_Konkour_Mashmool['konkour_field']==Reshte[j]].loc[Dataset_Konkour_Mashmool['Positive_Migration'] == 1]\n",
    "    Counter_Age=np.zeros(20)\n",
    "    Counter_Age_percent=np.zeros(20)\n",
    "    Counter_Age_Mashmool=np.zeros(20)\n",
    "    Counter_Age_Mashmool_percent=np.zeros(20)\n",
    "    for i in range(18):\n",
    "        Year=18+i\n",
    "        Counter_Age[i]=Data_Konkur_Migrated['Migration_Age'].value_counts()[Year]\n",
    "        Counter_Age_Mashmool[i]=Data_Konkur_Mashmool_Migrated['Migration_Age'].value_counts()[Year]\n",
    "    Counter_Age_sum=Counter_Age.sum()\n",
    "    Counter_Age_Mashmool_sum=Counter_Age_Mashmool.sum()\n",
    "    i=0\n",
    "    for i in range(18):\n",
    "        Counter_Age_percent[i]=(Counter_Age[i]/Counter_Age_sum)*100\n",
    "        Age_Matrix.append(Counter_Age_percent)\n",
    "    \n",
    "    Counter_Age_Mashmool_percent[i]=(Counter_Age_Mashmool[i]/Counter_Age_Mashmool_sum)*100\n",
    "    Age_Matrix_Mashmool.append(Counter_Age_Mashmool_percent)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b1bd1c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "Age_Matrix_Mashmool=pd.DataFrame(Age_Matrix_Mashmool)\n",
    "Age_Matrix_Mashmool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c61e1c57",
   "metadata": {},
   "outputs": [],
   "source": [
    "Counter_Age_percent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81fee333",
   "metadata": {},
   "outputs": [],
   "source": [
    "Data_Konkur_Migrated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23d21a23",
   "metadata": {},
   "outputs": [],
   "source": [
    "Reshte[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4efca19e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Counter_Riazi_Age"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84de174e",
   "metadata": {},
   "source": [
    "## 3 Migration vs Olympiad Results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe2dc14c",
   "metadata": {},
   "source": [
    "Here, we want to draw conclusions about migrants who have a contribution in konkour."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88a34c75",
   "metadata": {},
   "outputs": [],
   "source": [
    "Dataset_Olympiad=Dataset.dropna(subset = ['olympiad_date'])\n",
    "Dataset_Olympiad\n",
    "Check_Olympiad_Computer=Check_Olympiad.loc[Check_Olympiad['field']=='کامپیوتر']\n",
    "Check_Olympiad_Computer_90=Check_Olympiad_Computer.loc[Check_Olympiad['year']==1390]\n",
    "Check_Olympiad_Computer_90.loc[:,2:20]\n",
    "Check_Olympiad_Computer_90.rename(columns = {'Migration':1}, inplace = True)\n",
    "Check_Olympiad_Computer_90\n",
    "Check_Olympiad.rename(columns = {0:'Label2',1:'Migration'}, inplace = True)\n",
    "Check_Olympiad2=Check_Olympiad.dropna(subset = ['Label2'])\n",
    "Check_Olympiad2\n",
    "Check_Olympiad2['Migration'].value_counts()\n",
    "len(Dataset_Olympiad.loc[Dataset_Olympiad['Positive_Migration']==1])\n",
    "Dataset_Olympiad['Positive_Migration'].value_counts()\n",
    "Dataset_Olympiad['Negative_Migration'].value_counts()\n",
    "Dataset_Olympiad['Final_Status'].value_counts()\n",
    "Dataset_Olympiad['Current_Status'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56fc500e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Dataset_Olympiad.sort_values(by=['olympiad_date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c40fd9c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "Dataset_Olympiad_Riazi=Dataset_Olympiad.loc[Dataset_Olympiad['olympiad_field'] ==\"ریاضی\"].loc[Dataset_Olympiad['Positive_Migration'] == 1]\n",
    "Counter_Olympiad_Riazi=np.zeros(15)\n",
    "#Counter_Honar_percent=np.zeros(15)\n",
    "for i in range(15):\n",
    "    Year=1380+i\n",
    "    Counter_Olympiad_Riazi[i]=Dataset_Olympiad_Riazi['olympiad_date'].value_counts()[Year]\n",
    "    #Counter_Honar_percent[i]=Counter_Honar[i]/Pop_Honar[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4e2e4da",
   "metadata": {},
   "outputs": [],
   "source": [
    "Dataset_Olympiad_fizik=Dataset_Olympiad.loc[Dataset_Olympiad['olympiad_field'] ==\"فیزیک\"].loc[Dataset_Olympiad['Positive_Migration'] == 1]\n",
    "Counter_Olympiad_fizik=np.zeros(15)\n",
    "#Counter_Honar_percent=np.zeros(15)\n",
    "for i in range(15):\n",
    "    Year=1380+i\n",
    "    Counter_Olympiad_fizik[i]=Dataset_Olympiad_fizik['olympiad_date'].value_counts()[Year]\n",
    "    #Counter_Honar_percent[i]=Counter_Honar[i]/Pop_Honar[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c5ceb45",
   "metadata": {},
   "outputs": [],
   "source": [
    "Dataset_Olympiad_shimi=Dataset_Olympiad.loc[Dataset_Olympiad['olympiad_field'] ==\"شیمی\"].loc[Dataset_Olympiad['Positive_Migration'] == 1]\n",
    "Counter_Olympiad_shimi=np.zeros(15)\n",
    "#Counter_Honar_percent=np.zeros(15)\n",
    "for i in range(15):\n",
    "    Year=1380+i\n",
    "    Counter_Olympiad_shimi[i]=Dataset_Olympiad_shimi['olympiad_date'].value_counts()[Year]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "236689e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "Dataset_Olympiad_zist=Dataset_Olympiad.loc[Dataset_Olympiad['olympiad_field'] ==\"ادبی\"].loc[Dataset_Olympiad['Positive_Migration'] == 1]\n",
    "Counter_Olympiad_zist=np.zeros(15)\n",
    "#Counter_Honar_percent=np.zeros(15)\n",
    "for i in range(15):\n",
    "    Year=1380+i\n",
    "    Counter_Olympiad_zist[i]=Dataset_Olympiad_zist['olympiad_date'].value_counts()[Year]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69efbd1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "Dataset_Olympiad_computer=Dataset_Olympiad.loc[Dataset_Olympiad['olympiad_field'] ==\"کامپیوتر\"].loc[Dataset_Olympiad['Positive_Migration'] == 1]\n",
    "Counter_Olympiad_computer=np.zeros(15)\n",
    "#Counter_Honar_percent=np.zeros(15)\n",
    "for i in range(15):\n",
    "    Year=1380+i\n",
    "    Counter_Olympiad_computer[i]=Dataset_Olympiad_computer['olympiad_date'].value_counts()[Year]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd142143",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set width of bar\n",
    "barWidth = 0.17\n",
    "fig = plt.subplots(figsize =(12, 8))\n",
    " \n",
    "# # set height of bar\n",
    "# IT = [12, 30, 1, 8, 22]\n",
    "# ECE = [28, 6, 16, 5, 10]\n",
    "# CSE = [29, 3, 24, 25, 17]\n",
    "\n",
    "# Set position of bar on X axis\n",
    "br1 = np.arange(len(Counter_Olympiad_Riazi))\n",
    "br2 = [x + barWidth for x in br1]\n",
    "br3 = [x + barWidth for x in br2]\n",
    "br4 = [x + barWidth for x in br3]\n",
    "br5 = [x + barWidth for x in br4]\n",
    " \n",
    "# Make the plot\n",
    "plt.bar(br1, Counter_Olympiad_Riazi, color ='r', width = barWidth,\n",
    "        edgecolor ='grey', label ='Riazi', alpha=0.8)\n",
    "plt.bar(br2, Counter_Olympiad_fizik, color ='g', width = barWidth,\n",
    "        edgecolor ='grey', label ='ّFizik', alpha=0.8)\n",
    "plt.bar(br3, Counter_Olympiad_shimi, color ='b', width = barWidth,\n",
    "        edgecolor ='grey', label ='Shimi', alpha=0.8)\n",
    "plt.bar(br4, Counter_Olympiad_zist, color ='c', width = barWidth,\n",
    "        edgecolor ='grey', label ='Zist', alpha=0.8)\n",
    "plt.bar(br4, Counter_Olympiad_zist, color ='c', width = barWidth,\n",
    "        edgecolor ='grey', label ='Zist', alpha=0.8)\n",
    "\n",
    "# Adding Xticks\n",
    "#plt.xlabel('Year', fontweight ='bold', fontsize = 15)\n",
    "plt.xlabel('Year', fontsize = 15)\n",
    "plt.ylabel('Migrants (Person)', fontsize = 15)\n",
    "plt.xticks([r + barWidth for r in range(len(Counter_Olympiad_Riazi))],\n",
    "        ['1380', '1381', '1382', '1383', '1384','1385', '1386', '1387', '1388', '1389','1390', '1391', '1392', '1393','1394'])\n",
    " \n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d434f11f",
   "metadata": {},
   "outputs": [],
   "source": [
    "فیزیک، کامپیوتر، ریاضی، نجوم و اخترفیزیک، شیمی، ادبی، زیست شناسی"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6109f9c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyodbc\n",
    "\n",
    "conn = pyodbc.connect(r'Driver={Microsoft Access Driver (*.mdb, *.accdb)};DBQ=C:\\Users\\Marziyeh\\Downloads\\Estelam1.mdb;')\n",
    "cursor = conn.cursor()\n",
    "cursor.execute('select * from Javab_Taradod')\n",
    "   \n",
    "for row in cursor.fetchall():\n",
    "    print (row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4225f912",
   "metadata": {},
   "outputs": [],
   "source": [
    "msa_drivers = [x for x in pyodbc.drivers() if 'ACCESS' in x.upper()]\n",
    "print(f'MS-Access Drivers : {msa_drivers}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a436fcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    con_string = r'DRIVER={Microsoft Access Driver (*.mdb, *.accdb)};DBQ=C:\\Users\\Marziyeh\\Downloads\\Estelam1.mdb;'\n",
    "    conn = pyodbc.connect(con_string)\n",
    "    print(\"Connected To Database\")\n",
    " \n",
    " \n",
    " \n",
    "except pyodbc.Error as e:\n",
    "    print(\"Error in Connection\", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "880ce03d",
   "metadata": {},
   "outputs": [],
   "source": [
    "con_string = r'DRIVER={Microsoft Access Driver (*.mdb, *.accdb)};' \\\n",
    "             r'DBQ=C:\\Users\\Marziyeh\\Downloads\\Estelam1.mdb;'\n",
    "conn = pyodbc.connect(con_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdff61bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e66b0b1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyodbc\n",
    "\n",
    "conn = pyodbc.connect(r'Driver={Microsoft Access Driver (*.mdb, *.accdb)};DBQ=C:\\Users\\Marziyeh\\Downloads\\Estelam1.mdb;')\n",
    "cursor = conn.cursor()\n",
    "cursor.execute('select * from Javab_Taradod')\n",
    "   \n",
    "for row in cursor.fetchall():\n",
    "    print (row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6368e84e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# obtain all data in Person table\n",
    "cursor.execute('SELECT * FROM Javab_Taradod')\n",
    "values = cursor.fetchall()\n",
    "columns = [col[0] for col in cursor.description]\n",
    "\n",
    "# store data in data frame\n",
    "df = pd.DataFrame(values, columns=columns)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c1b4f3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "values"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "25e2432d8cb825db88c89f5d2409dfb998151ae4833636f6f1aa6fd0d034caaa"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
